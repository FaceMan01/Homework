{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN9FQuuPb0DtlJonmDigEOQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Кластеризации данных\n","\n","Для составления прогнозов воспользуемся классическим набором данных ирисов Фишера. Датасет представляет набор из 150 записей с пятью атрибутами в следующем порядке: длина чашелистика (sepal length), ширина чашелистика (sepal width), длина лепестка (petal length), ширина лепестка (petal width) и класс, соответствующий одному из трех видов: Iris Setosa, Iris Versicolor или Iris Virginica, обозначенных соответственно 0, 1, 2. Наш алгоритм должен принимать четыре свойства одного конкретного цветка и предсказывать, к какому классу (виду ириса) он принадлежит. Имеющиеся в наборе данных метки можно использовать для оценки качества предсказания.\n","\n","На диаграмме фиолетовым цветом обозначен вид Setosa, зеленым – Versicolor и желтым – Virginica.\n","\n","Для решения задач кластеризации используются Python, библиотеки scikit-learn, для загрузки и обработки набора данных и matplotlib, для визуализации. Ниже представлен программный код для исследования исходного набора данных."],"metadata":{"id":"5chvlxfDIAzD"}},{"cell_type":"code","source":["# Импортируем библиотеки\n","from sklearn import datasets\n","import matplotlib.pyplot as plt\n","\n","# Загружаем набор данных\n","iris_df = datasets.load_iris()\n","# Методы, доступные для набора данных\n","print(dir(iris_df))\n","# Признаки\n","print(iris_df.feature_names)\n","# Метки\n","print(iris_df.target)\n","# Имена меток\n","print(iris_df.target_names)\n","# Разделение набора данных\n","x_axis = iris_df.data[:, 0]  # Sepal Length\n","y_axis = iris_df.data[:, 1]  # Sepal Width\n","\n","# Построение\n","plt.xlabel(iris_df.feature_names[0])\n","plt.ylabel(iris_df.feature_names[1])\n","plt.scatter(x_axis, y_axis, c=iris_df.target)\n","plt.show()"],"metadata":{"id":"IRzle25dCCZh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Иерархическая кластеризация\n","\n","Иерархическая кластеризация, как следует из названия, представляет собой алгоритм, который строит иерархию кластеров. Этот алгоритм начинает работу с того, что каждому экземпляру данных сопоставляется свой собственный кластер. Затем два ближайших кластера объединяются в один и так далее, пока не будет образован один общий кластер.\n","\n","Результат иерархической кластеризации может быть представлен с помощью дендрограммы.\n","\n","Алгоритм кластеризации точно выделил класс Iris setosa и заметно отделил вид Iris virginica от Iris versicolor."],"metadata":{"id":"cb7d4holIAaU"}},{"cell_type":"code","source":["# Подключение библиотек\n","from scipy.cluster.hierarchy import linkage, dendrogram\n","from sklearn import datasets\n","import matplotlib.pyplot as plt\n","\n","# Создание полотна для рисования\n","fig = plt.figure(figsize=(15, 30))\n","fig.patch.set_facecolor('white')\n","# Загрузка набора данных \"Ирисы Фишера\"\n","iris = datasets.load_iris()\n","# Реализация иерархической кластеризации при помощи функции linkage\n","mergings = linkage(iris.data, method='ward')\n","# Построение дендрограммы. Разными цветами выделены автоматически определенные кластеры\n","R = dendrogram(mergings, labels=[iris.target_names[i] for i in iris.target], orientation = 'left', leaf_font_size = 12)\n","\n","# Отображение дендрограммы\n","plt.show()"],"metadata":{"id":"hymDU2gZAGkI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Итеративные методы кластерного анализа\n","\n","Одним из популярных алгоритмов кластеризации данных является ***метод k-средних***. Это итеративный алгоритм кластеризации, основанный на минимизации суммарных квадратичных отклонений точек кластеров от центроидов (средних координат) этих кластеров.\n","\n"],"metadata":{"id":"MkhjW2rZJ0k2"}},{"cell_type":"code","source":["# Импортируем библиотеки\n","from sklearn import datasets\n","from sklearn.cluster import KMeans\n","\n","# Загружаем набор данных\n","iris_df = datasets.load_iris()\n","# Описываем модель\n","model = KMeans(n_clusters=3)\n","# Проводим моделирование\n","model.fit(iris_df.data)\n","# Предсказание на единичном примере\n","predicted_label = model.predict([[7.2, 3.5, 0.8, 1.6]])\n","# Предсказание на всем наборе данных\n","all_predictions = model.predict(iris_df.data)\n","\n","# Выводим предсказания\n","print(predicted_label)\n","print(all_predictions)"],"metadata":{"id":"vvr14xJHCQS-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Сравнение метода k-средних с иерархической кластеризацией данных\n","\n","Иерархическая кластеризация хуже подходит для кластеризации больших объемов данных в сравнении с методом k-средних. Это объясняется тем, что временная сложность алгоритма линейна для метода k-средних (O(n)) и квадратична для метода иерархической кластеризации (O(n2))\n","\n","* Из центроидной геометрии построения метода k-средних следует, что метод хорошо работает, когда форма кластеров является гиперсферической (например, круг в 2D или сфера в 3D).\n","\n","* В кластеризации при помощи метода k-средних алгоритм начинает построение с произвольного выбора начальных точек, поэтому, результаты, генерируемые при многократном запуске алгоритма, могут отличаться. В то же время в случае иерархической кластеризации результаты воспроизводимы.\n","\n","* Метод k-средних более чувствителен к зашумленным данным, чем иерархический метод.\n","\n"],"metadata":{"id":"1Ndn4Dc4KsfC"}},{"cell_type":"markdown","source":["## Понижение размерности с методом t-SNE\n","\n","Метод t-SNE (t-distributed stochastic neighbor embedding) представляет собой один из методов обучения без учителя, используемых для визуализации, например, отображения пространства высокой размерности в двух- или трехмерное пространство. t-SNE расшифровывается как распределенное стохастическое соседнее вложение.\n","\n","Метод моделирует каждый объект пространства высокой размерности в двух- или трехкоординатную точку таким образом, что близкие по характеристикам элементы данных в многомерном пространстве (например, датасете с большим числом столбцов) проецируются в соседние точки, а разнородные объекты с большей вероятностью моделируются точками, далеко отстоящими друг от друга."],"metadata":{"id":"D-Fq4gVNKg76"}},{"cell_type":"code","source":["# Импорт библиотек\n","from sklearn import datasets\n","from sklearn.manifold import TSNE\n","import matplotlib.pyplot as plt\n","\n","# Загрузка датасета\n","iris_df = datasets.load_iris()\n","\n","# Определяем модель и скорость обучения\n","model = TSNE(learning_rate=100)\n","\n","# Обучаем модель\n","transformed = model.fit_transform(iris_df.data)\n","\n","# Представляем результат в двумерных координатах\n","x_axis = transformed[:, 0]\n","y_axis = transformed[:, 1]\n","\n","plt.scatter(x_axis, y_axis, c=iris_df.target)\n","plt.show()"],"metadata":{"id":"YvNxF2yBDGHf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Метод кластеризации на основе плотности DBSCAN\n","\n","DBSCAN (Density-Based Spatial Clustering of Applications with Noise, плотностной алгоритм пространственной кластеризации с присутствием шума) – популярный алгоритм кластеризации, используемый в анализе данных в качестве одной из замен метода k-средних."],"metadata":{"id":"bsGOzDQALd4z"}},{"cell_type":"code","source":["# Импортируем библиотеки\n","from sklearn.datasets import load_iris\n","import matplotlib.pyplot as plt\n","from sklearn.cluster import DBSCAN\n","from sklearn.decomposition import PCA\n","\n","# Загружаем датасет\n","iris = load_iris()\n","# Определяем модель\n","dbscan = DBSCAN()\n","# Обучаем\n","dbscan.fit(iris.data)\n","# Уменьшаем размерность при помощи метода главных компонент\n","pca = PCA(n_components=2).fit(iris.data)\n","pca_2d = pca.transform(iris.data)\n","\n","# Строим в соответствии с тремя классами\n","for i in range(0, pca_2d.shape[0]):\n","    if dbscan.labels_[i] == 0:\n","        c1 = plt.scatter(pca_2d[i, 0], pca_2d[i, 1], c='r', marker='+')\n","    elif dbscan.labels_[i] == 1:\n","        c2 = plt.scatter(pca_2d[i, 0], pca_2d[i, 1], c='g', marker='o')\n","    elif dbscan.labels_[i] == -1:\n","        c3 = plt.scatter(pca_2d[i, 0], pca_2d[i, 1], c='b', marker='*')\n","\n","plt.legend([c1, c2, c3], ['Кластер 1', 'Кластер 2', 'Шум'])\n","plt.title('DBSCAN нашел 2 кластера и шум')\n","plt.show()"],"metadata":{"id":"JVRQwj26D9Yc"},"execution_count":null,"outputs":[]}]}